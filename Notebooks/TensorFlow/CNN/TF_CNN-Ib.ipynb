{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>\n",
    "\n",
    "[source](https://medium.com/swlh/classifying-fashion-mnist-dataset-with-convolutional-neural-nets-dd092d755164)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install -U opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 11s 0us/step\n",
      "26435584/26421880 [==============================] - 11s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n",
      "4431872/4422102 [==============================] - 2s 0us/step\n",
      "Shape:\n",
      "X_Train (60000, 28, 28)\n",
      "Y_Train (60000,)\n",
      "X_Test (10000, 28, 28)\n",
      "Y_Test (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print('Shape:')\n",
    "print('X_Train {}'.format(x_train.shape))\n",
    "print('Y_Train {}'.format(y_train.shape))\n",
    "print('X_Test {}'.format(x_test.shape))\n",
    "print('Y_Test {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_samples(sample, plot=True):\n",
    "    counter = {}\n",
    "    for key in sample:\n",
    "        if key not in counter.keys():\n",
    "            counter[key] = 1\n",
    "        else:\n",
    "            counter[key] = counter[key] + 1\n",
    "    df_dict = {'cat':[x for x in counter.keys()], \n",
    "               'cnt':[y for y in  counter.values()]}\n",
    "    cnt_df = pd.DataFrame(df_dict)\n",
    "    if plot:\n",
    "        sns.barplot(data=cnt_df, x='cat', y='cnt')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('# of Obs. in each Category')\n",
    "        return None\n",
    "    else:\n",
    "        return cnt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_samples(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Image\n",
    "def scale_img(dim, img):\n",
    "    resized_img = cv2.resize(np.asarray(img), dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized_img\n",
    "\n",
    "#Normalize Image\n",
    "def normalize_img(img, is_gray = False):\n",
    "    normalized_img = cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX)\n",
    "    if is_gray:\n",
    "        cvt = cv2.cvtColor(normalized_img, cv2.COLOR_BGR2GRAY)\n",
    "        return cvt\n",
    "    return normalized_img\n",
    "\n",
    "#Rotate Image\n",
    "def rotate_img(img, rot_deg):\n",
    "    rows,cols = img.shape[0], img.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),rot_deg,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return dst\n",
    "\n",
    "#Translate Image\n",
    "def translate_img(img,x=100,y=50):\n",
    "    rows,cols = img.shape[0], img.shape[1]\n",
    "    M = np.float32([[1,0,x],[0,1,y]])\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "X_Train (180000, 28, 28, 1)\n",
      "Y_Train (180000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_tran = x_train.tolist()\n",
    "y_train_tran = y_train.tolist()\n",
    "ctr = 0\n",
    "for img in x_train:\n",
    "    x_train_tran.append(rotate_img(img, 90))\n",
    "    y_train_tran.append(y_train[ctr])\n",
    "    x_train_tran.append(translate_img(img, x=15, y=15))\n",
    "    y_train_tran.append(y_train[ctr])\n",
    "    ctr = ctr + 1\n",
    "    \n",
    "x_train_tran = np.array(x_train_tran).reshape(len(x_train_tran), 28, 28, 1)\n",
    "y_train_tran = tf.keras.utils.to_categorical(np.array(y_train_tran))\n",
    "#x_train_tran, y_train_tran = shuffle(x_train_tran, y_train_tran)\n",
    "\n",
    "print('Shape:')\n",
    "print('X_Train {}'.format(x_train_tran.shape))\n",
    "print('Y_Train {}'.format(y_train_tran.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.Sequential()\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5), activation='relu',input_shape=(28,28,1)))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(3,3)))\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(2,2), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "cnn_model.add(tf.keras.layers.Flatten())\n",
    "cnn_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dense(tf.keras.utils.to_categorical(y_train).shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 02:36:41.399494: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1128960000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 99s 17ms/step - loss: 1.0149 - accuracy: 0.6128\n",
      "Epoch 2/150\n",
      "5625/5625 [==============================] - 86s 15ms/step - loss: 0.7492 - accuracy: 0.7087\n",
      "Epoch 3/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.6901 - accuracy: 0.7293\n",
      "Epoch 4/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.6544 - accuracy: 0.7420\n",
      "Epoch 5/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.6296 - accuracy: 0.7531\n",
      "Epoch 6/150\n",
      "5625/5625 [==============================] - 69s 12ms/step - loss: 0.6108 - accuracy: 0.7601\n",
      "Epoch 7/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5938 - accuracy: 0.7665\n",
      "Epoch 8/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5839 - accuracy: 0.7707\n",
      "Epoch 9/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5742 - accuracy: 0.7740\n",
      "Epoch 10/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5678 - accuracy: 0.7767\n",
      "Epoch 11/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5619 - accuracy: 0.7784\n",
      "Epoch 12/150\n",
      "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5558 - accuracy: 0.7807\n",
      "Epoch 13/150\n",
      "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5499 - accuracy: 0.7829\n",
      "Epoch 14/150\n",
      "5625/5625 [==============================] - 64s 11ms/step - loss: 0.5442 - accuracy: 0.7841\n",
      "Epoch 15/150\n",
      "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5412 - accuracy: 0.7870\n",
      "Epoch 16/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5370 - accuracy: 0.7875\n",
      "Epoch 17/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5337 - accuracy: 0.7886\n",
      "Epoch 18/150\n",
      "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5291 - accuracy: 0.7900\n",
      "Epoch 19/150\n",
      "5625/5625 [==============================] - 63s 11ms/step - loss: 0.5251 - accuracy: 0.7917\n",
      "Epoch 20/150\n",
      "5625/5625 [==============================] - 63s 11ms/step - loss: 0.5242 - accuracy: 0.7922\n",
      "Epoch 21/150\n",
      "5625/5625 [==============================] - 63s 11ms/step - loss: 0.5206 - accuracy: 0.7931\n",
      "Epoch 22/150\n",
      "5625/5625 [==============================] - 63s 11ms/step - loss: 0.5186 - accuracy: 0.7944\n",
      "Epoch 23/150\n",
      "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5184 - accuracy: 0.7947\n",
      "Epoch 24/150\n",
      "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5131 - accuracy: 0.7956\n",
      "Epoch 25/150\n",
      "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5122 - accuracy: 0.7975\n",
      "Epoch 26/150\n",
      "5625/5625 [==============================] - 64s 11ms/step - loss: 0.5076 - accuracy: 0.7978\n",
      "Epoch 27/150\n",
      "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5090 - accuracy: 0.7989\n",
      "Epoch 28/150\n",
      "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5045 - accuracy: 0.8001\n",
      "Epoch 29/150\n",
      "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5060 - accuracy: 0.7990\n",
      "Epoch 30/150\n",
      " 657/5625 [==>...........................] - ETA: 1:13 - loss: 0.4881 - accuracy: 0.8040"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_tran\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tran\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Documents/env_default/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=15, verbose=2, mode='auto')\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(x_train_tran, y_train_tran, batch_size=32, epochs=150, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn_model.predict(x_test_tran)\n",
    "pred_list = []\n",
    "for i in preds:\n",
    "    pred_list.append(np.argmax(i))\n",
    "\n",
    "print('{}%'.format(accuracy_score(y_pred=pred_list,y_true=y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'T-shirt/top',\n",
    "             1:'Trouser',\n",
    "             2:'Pullover',\n",
    "             3:'Dress',\n",
    "             4:'Coat',\n",
    "             5:'Sandal',\n",
    "             6:'Shirt',\n",
    "             7:'Sneaker',\n",
    "             8:'Bag',\n",
    "             9:'Ankle boot'}\n",
    "\n",
    "true_class_ct = {}\n",
    "\n",
    "for i in range(10):\n",
    "    true_class_ct[class_map[i]] = sum(1 for x in incorrect_df['true'] if x == class_map[i])\n",
    "    pred_class_ct = {}\n",
    "for i in range(10):\n",
    "    pred_class_ct[class_map[i]] = sum(1 for x in incorrect_df['pred'] if x == class_map[i])\n",
    "    \n",
    "pred_class_ctop = {}\n",
    "\n",
    "def percentage_error(trueval, changedval, i):\n",
    "    op[class_map[i]] = ((changedval - trueval)/trueval) * 100\n",
    "    \n",
    "for ct in range(10):\n",
    "    tv = true_class_ct[class_map[ct]]\n",
    "    cv = pred_class_ct[class_map[ct]]\n",
    "    percentage_error(tv, cv, ct)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "width = 0.4\n",
    "x = np.arange(10)\n",
    "rects1 = ax.bar(x - width/2, list(true_class_ct.values()), width, label='True')\n",
    "rects2 = ax.bar(x + width/2, list(pred_class_ct.values()), width, label='CNN Predicted')\n",
    "\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Classification Error in each class')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(list(op.keys()))\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=list(op.keys()), y=list(op.values()))\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title('Percentage error for each class')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sneakers seems to be a problem. The model classified 60% more samples as sneakers than the original samples that were sneakers. Percentage, however, by itself is not enough. If we consider both bar charts, we can see that our model is overfitting few categories. There are few ways to avoid that.\n",
    "\n",
    "+ Regularization (L1/L2)\n",
    "+ Adding Dropout Layers\n",
    "+ Adding more data by data augmentation (which we did).\n",
    "\n",
    "Model fitting in my opinion is an iterative process. You begin with a model that you think has best hyperparameters to understand data. You then assess the model to see how well it performs on the training data using metrics like accuracy, loss etc. If the model seems to be not doing great, you tweak the hyperparameters and fit the model again until you reach a desired model. Hypothetically, a desired model is the one that has close to 100% accuracy and, that does not over or under-fit on training set and is not biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
